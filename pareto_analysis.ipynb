{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pareto Analysis"
      ],
      "metadata": {
        "id": "gKeKfChL1STk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Pareto Principle is a very famous analytical observation\n",
        "which states that roughly 20 % of the causes account for 80 %\n",
        "of the results.\n",
        "\n",
        "\n",
        "This observation is true for most of the scenarios such as\n",
        "\n",
        "\n",
        "\n",
        "*   About 80 % of the sales are made by about 20% of the\n",
        "customers in retail\n",
        "*   About 80% of suffering is due to 20% of the problems :P\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Here is the problem, You are given a retail sales dataset that\n",
        "contains customer_id, date, transaction_id, product_category,\n",
        "total_amount. You are asked - what is the percentage of total\n",
        "customers who account for about 80% of the total sales of each\n",
        "category that happened in the year 2023?"
      ],
      "metadata": {
        "id": "bKe6nWoM1HSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boiler Plate Code"
      ],
      "metadata": {
        "id": "9Jm377RK1mnv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13A1-zfZ-1jt"
      },
      "outputs": [],
      "source": [
        "# Import PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName(\"pareto_sql\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "Kjki8Tj_CpLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d mohammadtalib786/retail-sales-dataset"
      ],
      "metadata": {
        "id": "qFEVtvH2_wTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unpacing the zip file\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('retail-sales-dataset.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "dRmurVFeAMq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the data\n",
        "df1 = spark.read\\\n",
        "    .format(\"csv\")\\\n",
        "    .option(\"inferSchema\",\"true\")\\\n",
        "    .option(\"header\",\"true\")\\\n",
        "    .option(\"delimiter\",\",\")\\\n",
        "    .load(\"/content/retail_sales_dataset.csv\")"
      ],
      "metadata": {
        "id": "FiSUEnrY-_6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# renaming columns\n",
        "cols = df1.columns\n",
        "cols_new = [col.replace(\" \", \"_\").lower() for col in cols]\n",
        "df1 = df1.toDF(*cols_new)"
      ],
      "metadata": {
        "id": "yPYnVeSk__gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a view for Spark SQL\n",
        "df1.createOrReplaceTempView(\"sales\")"
      ],
      "metadata": {
        "id": "Aut35Iz_Apr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using DataFrames"
      ],
      "metadata": {
        "id": "oYGDZSXf1h5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering the df\n",
        "df1 = df1.filter(year(df1.date) == 2023)"
      ],
      "metadata": {
        "id": "6D-rv8g7C8oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1.\\\n",
        "  groupBy([\"product_category\",\"customer_id\"]).\\\n",
        "  agg(sum(\"total_amount\").alias(\"total_sales\"))"
      ],
      "metadata": {
        "id": "AJsa0oTtDgPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_main = df2.groupBy(\"product_category\").agg(count(\"*\").alias(\"counts\"))\n",
        "\n",
        "win_1 = Window.partitionBy(\"product_category\")\n",
        "\n",
        "df3 = df2.withColumn(\"cumulative_sales\", sum(\"total_sales\").over(win_1.orderBy(desc(\"total_sales\")).rowsBetween(Window.unboundedPreceding,Window.currentRow)))\n",
        "\n",
        "df4 = df3.withColumn(\"category_sales\", sum(\"total_sales\").over(win_1))\n",
        "\n",
        "df5 = df4.filter(df4.cumulative_sales <= 0.8 * df4.category_sales)\n",
        "\n",
        "df_pareto =  df5.groupBy(\"product_category\").agg(count(\"customer_id\").alias(\"customers\"))\n",
        "\n",
        "\n",
        "\n",
        "df_joined = df_main.join(df_pareto, \"product_category\", \"inner\")\n",
        "\n",
        "df_joined.selectExpr(\"product_category\", \"ROUND(customers/counts,2) as ratio\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJshsjCLEwDz",
        "outputId": "a464e0fc-6361-4b74-fd39-b2d7f0289911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----+\n",
            "|product_category|ratio|\n",
            "+----------------+-----+\n",
            "|          Beauty|  0.3|\n",
            "|        Clothing|  0.3|\n",
            "|     Electronics|  0.3|\n",
            "+----------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using SQL"
      ],
      "metadata": {
        "id": "xNe4unyV1bg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sql = spark.sql(\"\"\"\n",
        "WITH CTE1 as (\n",
        "  SELECT product_category, customer_id, SUM(total_amount) as total_sales\n",
        "  FROM sales\n",
        "  WHERE year(date) = 2023\n",
        "  GROUP BY product_category, customer_id\n",
        ")\n",
        ",\n",
        "CTE2 as (\n",
        "SELECT\n",
        "  product_category,\n",
        "  customer_id,\n",
        "  SUM(total_sales) OVER (PARTITION BY product_category) as total_sales,\n",
        "  COUNT(customer_id) OVER (PARTITION BY product_category) as total_customers,\n",
        "  SUM(total_sales) OVER (PARTITION BY product_category ORDER BY total_sales DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as cumulative_sales\n",
        "FROM CTE1\n",
        ")\n",
        "SELECT\n",
        "  product_category,\n",
        "\n",
        "  ROUND(COUNT(customer_id)/total_customers,2) as top_customers_ratio\n",
        "FROM CTE2\n",
        "WHERE cumulative_sales <= 0.8 * total_sales\n",
        "GROUP BY\n",
        "  product_category,\n",
        "  total_customers\n",
        ";\n",
        "\"\"\")\n",
        "\n",
        "df_sql.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIPiv1-IIdnc",
        "outputId": "1e9ed598-0e6a-4bfd-88f8-c7e24ca1fb6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-------------------+\n",
            "|product_category|top_customers_ratio|\n",
            "+----------------+-------------------+\n",
            "|          Beauty|                0.3|\n",
            "|        Clothing|                0.3|\n",
            "|     Electronics|                0.3|\n",
            "+----------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
